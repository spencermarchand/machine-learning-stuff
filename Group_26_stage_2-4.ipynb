{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "ENGR 418 Project Stage 2\n",
    "\n",
    "\n",
    "Group - 26\n",
    "\n",
    "\n",
    "Stuart Watts - 94854395\n",
    "\n",
    "Spencer Marchand - 42569939\n",
    "\n",
    "***\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import needed modules\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 818,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from numpy import asarray\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from PIL import Image, ImageFilter\n",
    "import math"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function Definition\n",
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to get image data from specified folder \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 819,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(folder,im_width,n_samples,angle):\n",
    "    file_names = os.listdir(folder)#make list of file names\n",
    "    #define empty arrays\n",
    "    x = np.empty((n_samples,im_width**2))\n",
    "    y = np.empty((n_samples,1))\n",
    "    #step through each image in the folder\n",
    "    for i in range(n_samples):\n",
    "        path = folder+file_names[i]\n",
    "        #extract image, convert to grey scale\n",
    "        im = Image.open(path).convert('L').rotate(angle)\n",
    "        #put image data into an array \n",
    "        im = im.resize((im_width, im_width))\n",
    "        im_array = asarray(im)\n",
    "        x[i,:] = im_array.reshape(1,-1)\n",
    "\n",
    "        # set up class labels\n",
    "        if file_names[i].startswith('c'):\n",
    "            y[i,:] = 0\n",
    "        elif file_names[i].startswith('r'):\n",
    "            y[i,:] = 1  \n",
    "        else:\n",
    "            y[i,:] = 2\n",
    "  \n",
    "    return x,y\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to get the number of files in a folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 820,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_samp_num(folder):\n",
    "    #make list of files in target folder\n",
    "    file_names = os.listdir(folder)\n",
    "    #return number of files in traget folder\n",
    "    n_samples = len(file_names)\n",
    "    return n_samples"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to return the sum of the edge data for each image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 821,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image_pix_sum(image_array,edge_thresh,peak_thresh,im_width):\n",
    "    # filter the data to find edges\n",
    "    image_array = (image_array-np.min(image_array))*255/(np.max(image_array)-np.min(image_array))\n",
    "    im = Image.fromarray(image_array.reshape(im_width,im_width)).convert('L')\n",
    "    edges_image = im.filter(ImageFilter.FIND_EDGES)\n",
    "    edges_array = np.asarray(edges_image)\n",
    "    edges_array_scaled = edges_array.copy()[1:im_width-1,1:im_width-1]\n",
    "    edges_array_scaled[edges_array_scaled < edge_thresh,] = 0 \n",
    "\n",
    "    # set up edge histograms\n",
    "    edges_v = np.sum(edges_array_scaled,axis=0).astype(float)\n",
    "    edges_h = np.sum(edges_array_scaled,axis=1).astype(float)\n",
    "\n",
    "    #initialize sums\n",
    "    v_sum = 0.\n",
    "    h_sum = 0.\n",
    "\n",
    "    #loop and add up histogram values\n",
    "    for i in range (im_width-2):\n",
    "        v_sum = v_sum + edges_v[i]\n",
    "        h_sum = h_sum + edges_h[i]\n",
    "    \n",
    "    return v_sum,h_sum"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to return the number on non zero columns and rows in the image passed to it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 822,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image_non0(image_array,edge_thresh,peak_thresh,im_width):\n",
    "    # filter the data to find edges\n",
    "    image_array = (image_array-np.min(image_array))*255/(np.max(image_array)-np.min(image_array))\n",
    "    im = Image.fromarray(image_array.reshape(im_width,im_width)).convert('L')\n",
    "    edges_image = im.filter(ImageFilter.FIND_EDGES)\n",
    "    edges_array = np.asarray(edges_image)\n",
    "    edges_array_scaled = edges_array.copy()[1:im_width-1,1:im_width-1]\n",
    "    edges_array_scaled[edges_array_scaled < edge_thresh,] = 0 \n",
    "    \n",
    "    # setup eadge histograms\n",
    "    edges_v = np.sum(edges_array_scaled,axis=0).astype(float)\n",
    "    edges_h = np.sum(edges_array_scaled,axis=1).astype(float)\n",
    "    \n",
    "    # initialize counters for number of non zero values\n",
    "    v_count = 0\n",
    "    h_count = 0\n",
    "\n",
    "    # count non zero columns and rows\n",
    "    for i in range (im_width-2):\n",
    "        if edges_v[i] != 0:\n",
    "            v_count += 1\n",
    "        if edges_h[i] !=0:\n",
    "            h_count += 1\n",
    "   \n",
    "    return v_count,h_count"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to return the average of the columns and rows in the image passed to it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 823,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image_pix_ave(image_array,edge_thresh,peak_thresh, im_width):\n",
    "    # filter the data to find edges\n",
    "    image_array = (image_array-np.min(image_array))*255/(np.max(image_array)-np.min(image_array))                  \n",
    "    im = Image.fromarray(image_array.reshape(im_width,im_width)).convert('L')\n",
    "    edges_image = im.filter(ImageFilter.FIND_EDGES)                                                                 \n",
    "    edges_array = np.asarray(edges_image)\n",
    "    edges_array_scaled = edges_array.copy()[1:im_width-1,1:im_width-1]\n",
    "    edges_array_scaled[edges_array_scaled < edge_thresh,] = 0 \n",
    "\n",
    "    #setup edge histograms\n",
    "    edges_v = np.sum(edges_array_scaled,axis=0).astype(float)\n",
    "    edges_h = np.sum(edges_array_scaled,axis=1).astype(float)\n",
    "\n",
    "    #initialize count and sum variables\n",
    "    v_count = 0                                                                                                    \n",
    "    h_count = 0                                                                                                  \n",
    "    edges_v_sum = 0                                                                                            \n",
    "    edges_h_sum = 0       \n",
    "\n",
    "    #loop through array indexes and calculate sum and number of non zero values\n",
    "    for i in range (im_width-2):\n",
    "        edges_v_sum += edges_v[i]                                                                       \n",
    "        if edges_v[i] != 0:\n",
    "            v_count += 1    \n",
    "        edges_h_sum += edges_h[i]                                                                     \n",
    "        if edges_h[i] !=0:\n",
    "            h_count += 1                                                                                         \n",
    "    \n",
    "    #calculate averages\n",
    "    ave_v = edges_v_sum/v_count                                                                               \n",
    "    ave_h = edges_h_sum/h_count   \n",
    "                                                                           \n",
    "    return ave_v,ave_h"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to return the norm of the columns and rows in the image passed to it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 824,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image_pix_norm(image_array,edge_thresh,peak_thresh, im_width):\n",
    "    # filter the data to find edges\n",
    "    image_array = (image_array-np.min(image_array))*255/(np.max(image_array)-np.min(image_array))       \n",
    "    im = Image.fromarray(image_array.reshape(im_width,im_width)).convert('L')\n",
    "    edges_image = im.filter(ImageFilter.FIND_EDGES)\n",
    "    edges_array = np.asarray(edges_image)\n",
    "    edges_array_scaled = edges_array.copy()[1:im_width-1,1:im_width-1]\n",
    "    edges_array_scaled[edges_array_scaled < edge_thresh,] = 0 \n",
    "\n",
    "    #setup edge histograms\n",
    "    edges_v = np.sum(edges_array_scaled,axis=0).astype(float)\n",
    "    edges_h = np.sum(edges_array_scaled,axis=1).astype(float)\n",
    "\n",
    "    #initialize count and sum variables\n",
    "    v_count = 0                                                                \n",
    "    h_count = 0                                                                  \n",
    "    edges_v_sum = 0                                                           \n",
    "    edges_h_sum = 0  \n",
    "\n",
    "    #loop through and calculate the sum of the squares                                       \n",
    "    for i in range (im_width-2):\n",
    "        edges_v_sum += edges_v[i] **2                 \n",
    "        edges_h_sum += edges_h[i] **2     \n",
    "\n",
    "    # root the sum of the squares                                                                           \n",
    "    norm_v = math.sqrt(edges_v_sum)                                                                                  \n",
    "    norm_h = math.sqrt(edges_h_sum)                                                                                  \n",
    "    return norm_v,norm_h"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to return the number of values above the standard deviation columns and rows in the image passed to it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 825,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image_above_std(image_array,edge_thresh,peak_thresh, im_width):\n",
    "    # filter the data to find edges\n",
    "    image_array = (image_array-np.min(image_array))*255/(np.max(image_array)-np.min(image_array))                   \n",
    "    im = Image.fromarray(image_array.reshape(im_width,im_width)).convert('L')\n",
    "    edges_image = im.filter(ImageFilter.FIND_EDGES)\n",
    "    edges_array = np.asarray(edges_image)\n",
    "    edges_array_scaled = edges_array.copy()[1:im_width-1,1:im_width-1]\n",
    "    edges_array_scaled[edges_array_scaled < edge_thresh,] = 0 \n",
    "    #setup edge histograms\n",
    "    edges_v = np.sum(edges_array_scaled,axis=0).astype(float)\n",
    "    edges_h = np.sum(edges_array_scaled,axis=1).astype(float)    \n",
    "\n",
    "    #initialize counters                                                                                                                                                                         \n",
    "    v_std_above = 0\n",
    "    h_std_above = 0          \n",
    "\n",
    "    #calculate the standard deviation of the non zero values                                                                                                                                                                  \n",
    "    v_std = np.std(np.ma.masked_equal(edges_v,0))  \n",
    "    h_std = np.std(np.ma.masked_equal(edges_h,0))  \n",
    "\n",
    "    #calculate the number of indexes above the standrd deviation\n",
    "    for i in range (im_width-2):\n",
    "        if (edges_v[i]>=(v_std)):\n",
    "            v_std_above += 1   \n",
    "        if (edges_h[i]>=(h_std)):\n",
    "            h_std_above += 1\n",
    "    return v_std_above,h_std_above"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to test a model and present the confusion matrix and accuracy score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 826,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function will test the model given to it with the data given to it\n",
    "def test(test_data,test_class,model):\n",
    "    # make prediction\n",
    "    y_pred = model.predict(test_data)\n",
    "\n",
    "    # print scores using the given data\n",
    "    print(\"Accuracy Score - \" , 100*accuracy_score(test_class,y_pred),\"%\")\n",
    "    print(\"\\nConfusion Matrix\\n\")\n",
    "    print(confusion_matrix(test_class,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable setup\n",
    "***\n",
    "\n",
    "**IMPORTANT** Change the path of the data when running on new machine\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 827,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define image width\n",
    "im_width = 64 \n",
    "\n",
    "# define path to training and testing folder, change when running on new machine or when data is moved\n",
    "folder_training = 'C:/Users/stuar/Documents/4th year/1st semester/engr 418/Project/Lego_dataset_2/Lego_dataset_2/training' + '/'  \n",
    "folder_testing =  'C:/Users/stuar/Documents/4th year/1st semester/engr 418/Project/Lego_dataset_2/Lego_dataset_2/testing' + '/' \n",
    "\n",
    "#define the number of samples in the target array\n",
    "n_training = get_samp_num(folder_training)\n",
    "n_testing = get_samp_num(folder_testing)\n",
    "\n",
    "#define empty arrays to be filled with training and test data\n",
    "x_train = np.empty((n_training,im_width**2))\n",
    "y_train = np.empty((n_training,1))\n",
    "x_test = np.empty((n_testing, im_width**2))\n",
    "y_test = np.empty((n_testing,1))\n",
    "\n",
    "#set variables for use in data processing\n",
    "ET = 64\n",
    "PT = 0.5\n",
    "\n",
    "#get image data \n",
    "x_train, y_train= get_data(folder_training, im_width,n_training,0)\n",
    "x_test, y_test= get_data(folder_testing, im_width,n_testing,0)\n",
    "\n",
    "#set up empty arrays for engineered features\n",
    "edge_features_train_pix_sum = np.zeros((n_training,2))\n",
    "edge_features_test_pix_sum = np.zeros((n_testing,2))\n",
    "edge_features_train_num_non0 = np.zeros((n_training,2))\n",
    "edge_features_test_num_non0 = np.zeros((n_testing,2))\n",
    "edge_features_train_pix_ave = np.zeros((n_training,2))\n",
    "edge_features_test_pix_ave = np.zeros((n_testing,2))\n",
    "edge_features_train_pix_norm = np.zeros((n_training,2))\n",
    "edge_features_test_pix_norm = np.zeros((n_testing,2))\n",
    "edge_features_train_above_std = np.zeros((n_training,2))\n",
    "edge_features_test_above_std = np.zeros((n_testing,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Engineering\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 828,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features complete\n"
     ]
    }
   ],
   "source": [
    "#loop through  images, get features\n",
    "for i in range(n_training):\n",
    "    # extract sum of histograms\n",
    "    edge_features_train_pix_sum[i,:] = process_image_pix_sum(x_train[i,:],ET,PT,im_width)\n",
    "    # extract number of non 0 indexes\n",
    "    edge_features_train_num_non0[i,:] = process_image_non0(x_train[i,:],ET,PT,im_width) \n",
    "    # extract the ave of the non zero values\n",
    "    edge_features_train_pix_ave[i,:] = process_image_pix_ave(x_train[i,:],ET,PT,im_width) \n",
    "    # extract the norm of the histograms\n",
    "    edge_features_train_pix_norm[i,:] = process_image_pix_norm(x_train[i,:],ET,PT,im_width) \n",
    "    # extact the number of indexes above he std\n",
    "    edge_features_train_above_std[i,:] = process_image_above_std(x_train[i,:],ET,PT,im_width) \n",
    "\n",
    "print(\"Training features complete\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 829,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing features complete\n"
     ]
    }
   ],
   "source": [
    "#loop through  images, get features\n",
    "for i in range(n_testing):\n",
    "    # extract sum of histograms\n",
    "    edge_features_test_pix_sum[i,:] = process_image_pix_sum(x_test[i,:],ET,PT,im_width) \n",
    "    # extract number of non 0 indexes   \n",
    "    edge_features_test_num_non0[i,:] = process_image_non0(x_test[i,:],ET,PT,im_width) \n",
    "    # extract the ave of the non zero values\n",
    "    edge_features_test_pix_ave[i,:] = process_image_pix_ave(x_test[i,:],ET,PT,im_width)\n",
    "    # extract the norm of the histograms \n",
    "    edge_features_test_pix_norm[i,:] = process_image_pix_norm(x_test[i,:],ET,PT,im_width) \n",
    "    # extact the number of indexes above the std\n",
    "    edge_features_test_above_std[i,:] = process_image_above_std(x_test[i,:],ET,PT,im_width)\n",
    "\n",
    "print(\"Testing features complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Selection\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 830,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False  True  True False False False  True  True False]\n"
     ]
    }
   ],
   "source": [
    "# combine features into one array for testing and one array for training\n",
    "features_train = np.hstack((edge_features_train_pix_sum,edge_features_train_num_non0,edge_features_train_pix_ave,\n",
    "edge_features_train_pix_norm,edge_features_train_above_std))\n",
    "features_test = np.hstack((edge_features_test_pix_sum,edge_features_test_num_non0,edge_features_test_pix_ave,\n",
    "edge_features_test_pix_norm,edge_features_test_above_std))\n",
    "\n",
    "#define the logistic pregression model\n",
    "model = LogisticRegression(max_iter=100000)\n",
    "\n",
    "#select the features\n",
    "sfs = SequentialFeatureSelector(model, n_features_to_select=4)\n",
    "sfs.fit(features_train, np.ravel(y_train))\n",
    "\n",
    "#show features that are used and not used\n",
    "print(sfs.get_support())\n",
    "\n",
    "#make array's of the selected features\n",
    "train_features_selected = sfs.transform(features_train)\n",
    "test_features_selected = sfs.transform(features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Training\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 831,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Test\n",
      "\n",
      "Accuracy Score -  100.0 %\n",
      "\n",
      "Confusion Matrix\n",
      "\n",
      "[[27  0  0]\n",
      " [ 0 27  0]\n",
      " [ 0  0 27]]\n"
     ]
    }
   ],
   "source": [
    "#train the model using the selected data\n",
    "model.fit(train_features_selected, np.ravel(y_train))\n",
    "\n",
    "#make sure data and model is properly set, we should be 100%\n",
    "print(\"Training Data Test\\n\")\n",
    "test(train_features_selected,y_train,model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Testing\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Data Test\n",
      "\n",
      "Accuracy Score -  97.53086419753086 %\n",
      "\n",
      "Confusion Matrix\n",
      "\n",
      "[[26  0  1]\n",
      " [ 0 27  0]\n",
      " [ 0  1 26]]\n"
     ]
    }
   ],
   "source": [
    "#test the model against the test data and display outcome\n",
    "print(\"Testing Data Test\\n\")\n",
    "test(test_features_selected,y_test,model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "70c7beaef8d5ffbc8b78002da42eff76d1e0eacf1346eea99ec5d1e6435fddb5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
